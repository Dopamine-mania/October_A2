# train.py
import os
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader, random_split
from diffusers import DDIMScheduler
from tqdm import tqdm
import numpy as np

from dataset import TimeSeriesDataset
from model import DiffusionModel

# --- é…ç½® (Configuration) ---
BATCH_SIZE = 32
NUM_EPOCHS = 10000
LEARNING_RATE = 1e-4
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
SAVE_DIR = "checkpoints_sle_baseline"  # checkpoints_sleï¼›checkpoints_sle_no_crossï¼›checkpoints_sle_no_selfï¼›checkpoints_sle_baseline
SAVE_EPOCH_FREQ = 500
VAL_FREQ = 100  # æ¯100ä¸ªepochåœ¨éªŒè¯é›†ä¸Šè¯„ä¼°ä¸€æ¬¡

# --- å‡†å¤‡å·¥ä½œ ---
os.makedirs(SAVE_DIR, exist_ok=True)

# 1. åˆå§‹åŒ–æ•°æ®å¹¶åˆ†å‰²
dataset_path = "./data/å¹³å‡_SLEæ‹‰æ›¼_500-2000_118æ‚£è€…åŠ å¯¹ç…§_æ ‡ç­¾_airPLS_smooth.xlsx"
full_dataset = TimeSeriesDataset(file_path=dataset_path, target_shape=(16, 32))

# åˆ†å‰²æ•°æ®é›†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›† (90% è®­ç»ƒ, 10% éªŒè¯)
train_size = int(0.9 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)
print(f"Dataset loaded. Train samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}")
print(f"Device set to: {DEVICE}")

# 2. åˆå§‹åŒ–æ¨¡å‹ã€ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
model = DiffusionModel(enable_self_attention=False, enable_cross_attention=False).to(DEVICE)  # æ¶ˆèå®éªŒ
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)
noise_scheduler = DDIMScheduler(num_train_timesteps=1000, beta_schedule="linear")

# --- è®­ç»ƒä¸éªŒè¯ ---
best_val_loss = float('inf')

for epoch in range(NUM_EPOCHS):
    # --- è®­ç»ƒéƒ¨åˆ† ---
    model.train()
    total_train_loss = 0
    progress_bar = tqdm(train_dataloader, desc=f"Epoch {epoch + 1}/{NUM_EPOCHS} [T]")
    
    for cond, image in progress_bar:
        cond, image = cond.to(DEVICE), image.to(DEVICE)
        B = cond.size(0)
        t = torch.randint(0, noise_scheduler.config.num_train_timesteps, (B,), device=DEVICE).long()
        noise = torch.randn_like(image)
        noisy_image = noise_scheduler.add_noise(image, noise, t)
        eps_pred = model(noisy_image, t, cond)
        loss = F.mse_loss(eps_pred, noise)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_train_loss += loss.item()
        progress_bar.set_postfix(train_loss=loss.item())
    
    avg_train_loss = total_train_loss / len(train_dataloader)

    # --- éªŒè¯éƒ¨åˆ† ---
    if (epoch + 1) % VAL_FREQ == 0:
        model.eval()
        total_val_loss = 0
        val_progress_bar = tqdm(val_dataloader, desc=f"Epoch {epoch + 1}/{NUM_EPOCHS} [V]")
        with torch.no_grad():
            for cond, image in val_progress_bar:
                cond, image = cond.to(DEVICE), image.to(DEVICE)
                B = cond.size(0)
                t = torch.randint(0, noise_scheduler.config.num_train_timesteps, (B,), device=DEVICE).long()
                noise = torch.randn_like(image)
                noisy_image = noise_scheduler.add_noise(image, noise, t)
                eps_pred = model(noisy_image, t, cond)
                val_loss = F.mse_loss(eps_pred, noise)
                total_val_loss += val_loss.item()
                val_progress_bar.set_postfix(val_loss=val_loss.item())
        
        avg_val_loss = total_val_loss / len(val_dataloader)
        print(f"Epoch {epoch + 1} | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}")

        # --- ä¿å­˜æœ€ä½³æ¨¡å‹ ---
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_model_path = os.path.join(SAVE_DIR, "best_model.pt")
            torch.save(model.state_dict(), best_model_path)
            print(f"âœ¨ New best model saved with Val Loss: {best_val_loss:.6f} at {best_model_path}")

    # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆç”¨äºæ–­ç‚¹ç»­è®­ï¼‰
    if (epoch + 1) % SAVE_EPOCH_FREQ == 0:
        ckpt_path = os.path.join(SAVE_DIR, f"model_epoch_{epoch + 1}.pt")
        torch.save(model.state_dict(), ckpt_path)
        print(f"âœ… Checkpoint saved to {ckpt_path}")

print("ğŸ‰ Training finished!")
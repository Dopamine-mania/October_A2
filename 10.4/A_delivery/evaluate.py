# evaluation.py
import torch
from torch.utils.data import DataLoader, random_split
from diffusers import DDIMScheduler
import pandas as pd
import numpy as np
from tqdm import tqdm
import os

from model import DiffusionModel
from dataset import TimeSeriesDataset

# ç¡®ä¿ä½ å·²ç»å®‰è£…äº† scipy: pip install scipy
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import mean_squared_error
from scipy.stats import pearsonr, wasserstein_distance

# --- é…ç½® (Configuration) ---
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
BATCH_SIZE = 16  # å¯ä»¥é€‚å½“å¢å¤§æ‰¹é‡ï¼ŒåŠ å¿«è¯„ä¼°é€Ÿåº¦

# !! å…³é”®: ç¡®ä¿è¿™ä¸ªè·¯å¾„æŒ‡å‘ä½ è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜çš„â€œæœ€ä½³â€æ¨¡å‹ !!
MODEL_PATH = "checkpoints_sle_baseline/best_model.pt" 

# !! å…³é”®: ç¡®ä¿æ•°æ®æ–‡ä»¶è·¯å¾„æ­£ç¡® !!
DATASET_PATH = "./data/å¹³å‡_SLEæ‹‰æ›¼_500-2000_118æ‚£è€…åŠ å¯¹ç…§_æ ‡ç­¾_airPLS_smooth.xlsx"

# --- å‡½æ•°å®šä¹‰ ---
def calculate_all_metrics(generated_flat, ground_truth_flat):
    """è®¡ç®—æ‰€æœ‰å››ä¸ªè¯„ä¼°æŒ‡æ ‡"""
    # ç¡®ä¿æ•°æ®æ˜¯ä¸€ç»´çš„
    generated_flat = generated_flat.flatten()
    ground_truth_flat = ground_truth_flat.flatten()
    
    # 1. å‡æ–¹è¯¯å·® (MSE)
    mse = mean_squared_error(ground_truth_flat, generated_flat)
    
    # 2. ä½™å¼¦ç›¸ä¼¼åº¦ (CS)
    cos_sim = cosine_similarity(ground_truth_flat.reshape(1, -1), generated_flat.reshape(1, -1))[0, 0]
    
    # 3. çš®å°”é€Šç›¸å…³ç³»æ•° (PCC)
    pcc, _ = pearsonr(ground_truth_flat, generated_flat)
    
    # 4. ç“¦ç‘Ÿæ–¯å¦è·ç¦» (WD)
    wd = wasserstein_distance(ground_truth_flat, generated_flat)
    
    return mse, cos_sim, pcc, wd

# --- ä¸»è¯„ä¼°é€»è¾‘ ---
print(f"Device set to: {DEVICE}")

# 1. åŠ è½½æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„åˆ†å‰²æ–¹å¼è·å–éªŒè¯é›†
full_dataset = TimeSeriesDataset(file_path=DATASET_PATH, target_shape=(16, 32))
train_size = int(0.9 * len(full_dataset))
val_size = len(full_dataset) - train_size
# è®¾ç½®å›ºå®šçš„éšæœºç§å­ï¼Œç¡®ä¿æ¯æ¬¡åˆ†å‰²ç»“æœéƒ½ä¸€æ ·
torch.manual_seed(0)
_, val_dataset = random_split(full_dataset, [train_size, val_size])
torch.manual_seed(torch.initial_seed()) # æ¢å¤éšæœºæ€§

dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)
print(f"Evaluation will be performed on {len(val_dataset)} validation samples.")

# ----------
# # evaluation.py (ä¿®æ”¹åï¼Œç”¨äºå®Œæ•´æ•°æ®é›†è¯„ä¼°)
# full_dataset = TimeSeriesDataset(file_path=DATASET_PATH, target_shape=(16, 32))


# # ç›´æ¥ä½¿ç”¨ full_dataset
# dataloader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=False)
# print(f"Evaluation will be performed on {len(full_dataset)} FULL samples.")


# 2. åŠ è½½æ¨¡å‹

model = DiffusionModel(enable_self_attention=False, enable_cross_attention=False).to(DEVICE)    # model = DiffusionModel(enable_self_attention=True, enable_cross_attention=False)
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
model.eval()
print(f"Model loaded from {MODEL_PATH}")

# 3. åˆå§‹åŒ–è°ƒåº¦å™¨
scheduler = DDIMScheduler(num_train_timesteps=1000, beta_schedule="linear")
scheduler.set_timesteps(50)

# 4. å¾ªç¯ç”Ÿæˆå¹¶è¯„ä¼°
all_metrics = []
all_generated_spectra = []
all_ground_truth_spectra = []

for cond, image_gt in tqdm(dataloader, desc="Evaluating"):
    cond, image_gt = cond.to(DEVICE), image_gt.to(DEVICE)
    
    noisy_image = torch.randn(image_gt.shape, device=DEVICE)


    for t in scheduler.timesteps:
        # è·å–å½“å‰æ‰¹æ¬¡å¤§å°
        batch_size = noisy_image.shape[0]
        
        # åˆ›å»ºä¸€ä¸ªä¸å›¾åƒæ‰¹æ¬¡å¤§å°ç›¸åŒçš„ t å¼ é‡
        t_batch = torch.full((batch_size,), t, device=DEVICE, dtype=torch.long)
        
        with torch.no_grad():
            # å°† t_batch é€å…¥æ¨¡å‹ï¼Œè€Œä¸æ˜¯å•ä¸ªçš„ t
            eps_pred = model(noisy_image, t_batch, cond)
            
        noisy_image = scheduler.step(eps_pred, t, noisy_image).prev_sample
    
    # å°†ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®é€ä¸ªå¤„ç†
    for i in range(image_gt.shape[0]):
        gen_img = noisy_image[i]
        gt_img = image_gt[i]
        
        original_len = val_dataset.dataset.original_feature_len # ä»åŸå§‹æ•°æ®é›†ä¸­è·å–   æ ¹æ®æµ‹è¯•éªŒè¯é›†æˆ–å…¨é›†æ›´æ”¹
        
        gen_padded = gen_img.squeeze().cpu().numpy().flatten()
        gen_original = gen_padded[:original_len]

        gt_padded = gt_img.squeeze().cpu().numpy().flatten()
        gt_original = gt_padded[:original_len]
        
        metrics = calculate_all_metrics(gen_original, gt_original)
        all_metrics.append(metrics)
        
        # ä¿å­˜å…‰è°±ç”¨äºåç»­åˆ†æï¼ˆå¯é€‰ï¼‰
        max_val = val_dataset.dataset.raw_features_max
        all_generated_spectra.append(gen_original * max_val)
        all_ground_truth_spectra.append(gt_original * max_val)

# 5. è®¡ç®—å¹¶æ‰“å°å¹³å‡æŒ‡æ ‡
metrics_array = np.array(all_metrics)
avg_metrics = np.mean(metrics_array, axis=0)

print("\n--- ğŸ“Š Final Evaluation Results ---")
print(f"Mean Squared Error (MSE):      {avg_metrics[0]:.6f}")
print(f"Cosine Similarity (CS):        {avg_metrics[1]:.6f}")
print(f"Pearson Correlation (PCC):     {avg_metrics[2]:.6f}")
print(f"Wasserstein Distance (WD):     {avg_metrics[3]:.6f}")
print("------------------------------------")

# ä¿å­˜ç”Ÿæˆçš„æ•°æ®åˆ°Excel
df_generated = pd.DataFrame(all_generated_spectra)
df_generated.to_excel("generated_sle_spectra_baseline.xlsx", index=False, header=False)
print("âœ… Generated spectra saved to generated_sle_spectra_baseline.xlsx")